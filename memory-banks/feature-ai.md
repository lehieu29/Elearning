# T√≠nh NƒÉng AI Trong D·ª± √Ån E-Learning

D·ª± √°n E-Learning t√≠ch h·ª£p Google Generative AI (Gemini) ƒë·ªÉ cung c·∫•p tr·∫£i nghi·ªám h·ªçc t·∫≠p t∆∞∆°ng t√°c v√† th√¥ng minh. T√≠nh nƒÉng AI ƒë∆∞·ª£c s·ª≠ d·ª•ng ch·ªß y·∫øu trong vi·ªác t·∫°o transcript, tr·∫£ l·ªùi c√¢u h·ªèi li√™n quan ƒë·∫øn n·ªôi dung b√†i h·ªçc, v√† sinh t√≥m t·∫Øt.

## 1. T·ªïng Quan T√≠nh NƒÉng AI

### C√°c t√≠nh nƒÉng ch√≠nh
- Chat bot tr·ª£ gi√∫p trong qu√° tr√¨nh h·ªçc
- T·ª± ƒë·ªông sinh transcript (ph·ª• ƒë·ªÅ) cho video b√†i gi·∫£ng
- T√≥m t·∫Øt n·ªôi dung b√†i h·ªçc
- Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ng·ªØ c·∫£nh c·ªßa b√†i h·ªçc
- Gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ l·∫≠p tr√¨nh v√† k·ªπ thu·∫≠t

### C√¥ng ngh·ªá s·ª≠ d·ª•ng
- **Google Generative AI (Gemini)**: Model gemini-1.0-pro-001
- **Socket.IO**: Giao ti·∫øp realtime gi·ªØa client v√† server
- **FFmpeg**: X·ª≠ l√Ω video v√† audio ƒë·ªÉ t·∫°o transcript

## 2. Ki·∫øn Tr√∫c AI

```mermaid
graph TD
    A[Client] -->|1. G·ª≠i c√¢u h·ªèi| B[Frontend: AiChat Component]
    B -->|2. G·ª≠i prompt| C[Google Generative AI API]
    C -->|3. Tr·∫£ v·ªÅ k·∫øt qu·∫£| B
    B -->|4. Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi| A
    
    E[Video B√†i H·ªçc] -->|1. Upload| F[Backend: Controller]
    F -->|2. T√°ch audio| G[FFmpeg]
    G -->|3. Audio file| H[AI Transcription Service]
    H -->|4. L∆∞u transcript| I[Database]
    
    A -->|1. Y√™u c·∫ßu transcript| J[Backend API]
    J -->|2. L·∫•y transcript| I
    J -->|3. Tr·∫£ v·ªÅ transcript| A
    A -->|4. D√πng transcript l√†m ng·ªØ c·∫£nh| B
```

## 3. C√†i ƒê·∫∑t Components

### 3.1. Frontend AI Chat Component

```tsx
// Frontend/app/components/AI/AiChat.tsx
"use client";
import React, { FC, useState, useEffect } from "react";
import { FetchBaseQueryError } from "@reduxjs/toolkit/query";
import {
  GoogleGenerativeAI,
  HarmCategory,
  HarmBlockThreshold,
} from "@google/generative-ai";
import { styles } from "@/app/styles/style";
import { ThemeSwitcher } from "@/app/utils/ThemeSwitcher";
import Link from "next/link";
import { useGetTranscriptMutation } from "@/redux/features/courses/coursesApi";
import { useParams } from "next/navigation";
import Loader from "../Loader/Loader";

type Props = {
  videoName: string;
};

interface Message {
  text: string;
  role: "user" | "bot";
  timestamp: Date;
}

interface ChatSession {
  sendMessage: (message: string) => Promise<any>;
}

const AiChat: FC<Props> = ({ videoName }) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [userInput, setUserInput] = useState("");
  const [chat, setChat] = useState<ChatSession | null>(null);
  const [transcript, setTranscript] = useState<string | undefined>("");
  const [courseName, setCourseName] = useState<string | undefined>("");
  const [err, setErr] = useState<string | null>(null);
  
  // C·∫•u h√¨nh API key v√† model
  const MODEL_NAME = "gemini-1.0-pro-001";
  const API_KEY = "AIzaSyBTFD1gqjU7NPBnPX88RiFBC3kQSDVqy2c";
  const genAI = new GoogleGenerativeAI(API_KEY);
  
  const courseId = useParams();
  const [getTranscript, { data, isLoading, error }] =
    useGetTranscriptMutation();

  // C·∫•u h√¨nh generation parameters
  const generationConfig = {
    temperature: 0.9,
    topK: 1,
    topP: 1,
    maxOutputTokens: 2048,
  };
  
  // C·∫•u h√¨nh safety settings
  const safetySettings = [
    {
      category: HarmCategory.HARM_CATEGORY_HARASSMENT,
      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    {
      category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    {
      category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    {
      category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
  ];

  // Kh·ªüi t·∫°o chat session
  useEffect(() => {
    const initChat = async () => {
      try {
        const newChat: any = await genAI
          .getGenerativeModel({ model: MODEL_NAME })
          .startChat({
            generationConfig,
            safetySettings,
            history: [...messages].map((msg: Message) => ({
              parts: [{ text: msg.text }],
              role: msg.role === "bot" ? "model" : msg.role,
            })),
          });
        setChat(newChat);
      } catch (err: any) {
        setErr("Something Went Wrong!");
      }
    };
    initChat();
  }, [transcript, courseName]);

  // X·ª≠ l√Ω g·ª≠i tin nh·∫Øn
  const handleSendMessage = async () => {
    try {
      const userMessage: Message = {
        text: userInput,
        role: "user",
        timestamp: new Date(),
      };

      setMessages((prevMessages) => [...prevMessages, userMessage]);
      setUserInput("");
      
      if (chat) {
        let trs: string = transcript
          ? `Use following Transcript if required NOT Compulsory - "${transcript}" and`
          : "and";
          
        // T·∫°o prompt v·ªõi ng·ªØ c·∫£nh
        const prompt: string = `QUESTION - ${userInput} Answer the following question and provide answer in context to concepts associated with ${videoName} or ${courseName} only, 
        ${trs} 
        If question is out of context or not related to programming then just Send Response as "Please ask questions only related to ${videoName}".`;
        
        // G·ª≠i prompt ƒë·∫øn AI
        const result = await chat.sendMessage(prompt);
        
        // Th√™m c√¢u tr·∫£ l·ªùi v√†o danh s√°ch tin nh·∫Øn
        const botMessage: Message = {
          text: result.response.text(),
          role: "bot",
          timestamp: new Date(),
        };
        
        setMessages((prevMessages) => [...prevMessages, botMessage]);
      }
    } catch (err: any) {
      setErr("Something is wrong");
    }
  };

  // X·ª≠ l√Ω ph√≠m Enter
  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === "Enter") {
      e.preventDefault(); // prevent adding new Line
      handleSendMessage();
    }
  };

  // L·∫•y transcript c·ªßa video
  const handleGetTranscript = async () => {
    try {
      const result = await getTranscript({
        id: courseId?.id,
        videoName,
      });
      
      if (result && "data" in result) {
        let trs: string | undefined = result?.data?.transcript;
        setTranscript(trs);

        let cname: string | undefined = result?.data?.courseName;
        setCourseName(cname);
      }
      
      // T·∫°o c√¢u tr·∫£ l·ªùi t√≥m t·∫Øt ngay khi c√≥ transcript
      if (chat && courseName) {
        let noTRS: string = `mention "No transcript available for course!, But still here is a short summary on ${videoName}" and provide 3-4 line summary for ${videoName}`;
        let yesTRS: string = `Summarize the following transcript - ${transcript} in context to ${courseName}`;
        const prompt: string = transcript ? yesTRS : noTRS;
        
        const result = await chat.sendMessage(prompt);
        
        const botMessage: Message = {
          text: result.response.text(),
          role: "bot",
          timestamp: new Date(),
        };
        
        setMessages((prevMessages) => [...prevMessages, botMessage]);
      } else {
        alert("Try Again");
      }
    } catch (err) {
      console.error("Error fetching transcript:", err);
    }
  };

  return (
    <>
      {isLoading ? (
        <Loader />
      ) : (
        <div className="flex flex-col h-screen p-4">
          <button
            className="p-2 bg-red-500 self-center rounded-full text-white hover:bg-red-400"
            onClick={handleGetTranscript}
          >
            Summarize
          </button>
          <div className="flex justify-between items-center mb-4">
            <Link href={"/"} className={`${styles.title} !text-2xl`}>
              ELearning AI BOT ü§ñ
            </Link>
            <div className="flex space-x-2">
              <ThemeSwitcher />
            </div>
          </div>
          <div className="flex-1 overflow-y-auto rounded-md p-2">
            {/* Hi·ªÉn th·ªã tin nh·∫Øn */}
            {[...messages].map((msg, index) => (
              <div
                key={index}
                className={`mb-4 ${
                  msg.role === "user" ? "text-right" : "text-left"
                }`}
              >
                <span
                  className={` ${
                    msg.role === "user"
                      ? `${styles.input}`
                      : " rounded-lg font-Josefin p-2 text-xl text-black dark:text-white bg-blue-200 dark:bg-blue-950 "
                  }`}
                >
                  {msg.text}
                </span>
                <p className={`text-xs ${styles.label} mt-1`}>
                  {msg.role === "bot" ? "Bot" : "You"} -{" "}
                  {msg.timestamp.toLocaleTimeString()}
                </p>
              </div>
            ))}
            {err && <div className="text-red-500 text-sm mb-4">{err}</div>}
            
            {/* Input tin nh·∫Øn */}
            <div className="flex items-center mt-4">
              <input
                type="text"
                placeholder="Type your message..."
                value={userInput}
                onChange={(e) => setUserInput(e.target.value)}
                onKeyDown={handleKeyPress}
                className={`${styles.input} !rounded-l-md !flex-1 !p-2 !border-b !border-t !border-l focus:outline-none focus:border-blue-500 `}
              />
              <button
                onClick={handleSendMessage}
                className={`p-2 cursor-pointer bg-[#2190ff] text-white rounded-r-md ml-1 mt-1  hover:bg-opacity-80 focus:outline-none`}
              >
                Send
              </button>
            </div>
          </div>
        </div>
      )}
    </>
  );
};

export default AiChat;
```

### 3.2. Backend API cho Transcript

```typescript
// Backend/controller/course.controller.ts
export const getTranscript = catchAsyncErrors(
  async (req: Request, res: Response, next: NextFunction) => {
    try {
      const { id, videoName } = req.body;

      // T√¨m kh√≥a h·ªçc
      const course = await CourseModel.findById(id);
      if (!course) {
        return next(new ErrorHandler("Course not found", 404));
      }

      // T√¨m subtitle trong database
      const subtitle = await SubtitleModel.findOne({
        courseId: id,
        fileName: videoName,
      });

      // N·∫øu c√≥ subtitle, tr·∫£ v·ªÅ
      if (subtitle) {
        return res.status(200).json({
          success: true,
          transcript: subtitle.transcript,
          courseName: course.name,
        });
      }

      // N·∫øu kh√¥ng c√≥, tr·∫£ v·ªÅ r·ªóng
      return res.status(200).json({
        success: true,
        transcript: "",
        courseName: course.name,
      });
    } catch (error: any) {
      return next(new ErrorHandler(error.message, 500));
    }
  }
);
```

### 3.3. Backend Service cho Transcript Generation

```typescript
// Backend/services/ai.service.ts
import ffmpeg from 'fluent-ffmpeg';
import fs from 'fs-extra';
import path from 'path';
import { GoogleGenerativeAI } from "@google/generative-ai";

// Kh·ªüi t·∫°o Google Generative AI
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");
const model = genAI.getGenerativeModel({ model: "gemini-1.0-pro-001" });

export const generateTranscript = async (videoPath: string, fileName: string, courseId: string): Promise<string> => {
  try {
    // Th∆∞ m·ª•c l∆∞u file t·∫°m
    const tempDir = path.join(__dirname, '../temp');
    await fs.ensureDir(tempDir);

    // ƒê∆∞·ªùng d·∫´n cho file audio
    const audioPath = path.join(tempDir, `${path.basename(videoPath, path.extname(videoPath))}.mp3`);

    // Tr√≠ch xu·∫•t audio t·ª´ video
    await new Promise<void>((resolve, reject) => {
      ffmpeg(videoPath)
        .output(audioPath)
        .audioCodec('libmp3lame')
        .on('end', () => resolve())
        .on('error', (err) => reject(err))
        .run();
    });

    // ƒê·ªçc file audio d∆∞·ªõi d·∫°ng base64
    const audioData = await fs.readFile(audioPath, { encoding: 'base64' });

    // G·ª≠i y√™u c·∫ßu ƒë·∫øn AI ƒë·ªÉ t·∫°o transcript
    const prompt = `
      You are a professional transcription service. 
      Transcribe the following audio to text.
      Return only the transcript, without any additional explanation or notes.
      Please maintain any technical terms and code snippets if they appear in the audio.
    `;

    const result = await model.generateContent([
      prompt,
      { audio: audioData }
    ]);

    const transcript = result.response.text();

    // X√≥a file t·∫°m
    await fs.remove(audioPath);

    // L∆∞u transcript v√†o database
    const subtitle = new SubtitleModel({
      courseId,
      fileName,
      transcript,
    });

    await subtitle.save();

    return transcript;
  } catch (error) {
    console.error('Error generating transcript:', error);
    throw error;
  }
};
```

### 3.4. Backend Model cho Subtitle

```typescript
// Backend/models/subtitle.model.ts
import mongoose, { Document, Model, Schema } from "mongoose";

export interface ISubtitle extends Document {
  courseId: string;
  fileName: string;
  transcript: string;
}

const subtitleSchema = new Schema<ISubtitle>({
  courseId: {
    type: String,
    required: true,
  },
  fileName: {
    type: String,
    required: true,
  },
  transcript: {
    type: String,
    required: true,
  },
}, {
  timestamps: true,
});

// T·∫°o index ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô truy v·∫•n
subtitleSchema.index({ courseId: 1, fileName: 1 }, { unique: true });

const SubtitleModel: Model<ISubtitle> = mongoose.model("Subtitle", subtitleSchema);

export default SubtitleModel;
```

## 4. Lu·ªìng X·ª≠ L√Ω Ch√≠nh

### 4.1. T·∫°o Transcript Cho Video

```mermaid
sequenceDiagram
    participant Admin
    participant Backend
    participant FFmpeg
    participant GoogleAI
    participant Database
    
    Admin->>Backend: Upload video b√†i h·ªçc
    Backend->>Backend: L∆∞u video tr√™n Cloudinary
    Backend->>FFmpeg: Tr√≠ch xu·∫•t audio t·ª´ video
    FFmpeg->>Backend: Tr·∫£ v·ªÅ file audio
    Backend->>GoogleAI: G·ª≠i file audio + prompt
    GoogleAI->>Backend: Tr·∫£ v·ªÅ transcript
    Backend->>Database: L∆∞u transcript
```

1. **Upload Video**:
   - Admin upload video kh√≥a h·ªçc l√™n h·ªá th·ªëng
   - Backend l∆∞u video tr√™n Cloudinary

2. **T·∫°o Transcript**:
   - Backend s·ª≠ d·ª•ng FFmpeg ƒë·ªÉ tr√≠ch xu·∫•t audio t·ª´ video
   - Audio ƒë∆∞·ª£c g·ª≠i ƒë·∫øn Google Generative AI v·ªõi prompt y√™u c·∫ßu t·∫°o transcript
   - AI tr·∫£ v·ªÅ transcript d·∫°ng text

3. **L∆∞u Tr·ªØ**:
   - Transcript ƒë∆∞·ª£c l∆∞u v√†o MongoDB v·ªõi courseId v√† fileName
   - S·∫µn s√†ng ƒë∆∞·ª£c s·ª≠ d·ª•ng cho t√≠nh nƒÉng AI Chat

### 4.2. AI Chat Trong Kh√≥a H·ªçc

```mermaid
sequenceDiagram
    participant Student
    participant Frontend
    participant Backend
    participant MongoDB
    participant GoogleAI
    
    Student->>Frontend: M·ªü AI Chat trong b√†i h·ªçc
    Frontend->>Backend: Y√™u c·∫ßu transcript (videoName, courseId)
    Backend->>MongoDB: T√¨m transcript
    MongoDB->>Backend: Tr·∫£ v·ªÅ transcript
    Backend->>Frontend: G·ª≠i transcript
    Frontend->>GoogleAI: Kh·ªüi t·∫°o chat session v·ªõi context
    GoogleAI->>Frontend: T·∫°o t√≥m t·∫Øt n·ªôi dung
    Frontend->>Student: Hi·ªÉn th·ªã t√≥m t·∫Øt
    
    Student->>Frontend: ƒê·∫∑t c√¢u h·ªèi
    Frontend->>GoogleAI: G·ª≠i prompt v·ªõi context t·ª´ transcript
    GoogleAI->>Frontend: Tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi
    Frontend->>Student: Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi
```

1. **Kh·ªüi T·∫°o Chat**:
   - H·ªçc vi√™n m·ªü AI Chat khi xem video b√†i h·ªçc
   - Frontend g·ªçi API ƒë·ªÉ l·∫•y transcript c·ªßa video
   - Frontend kh·ªüi t·∫°o chat session v·ªõi Google Generative AI

2. **T√≥m T·∫Øt N·ªôi Dung**:
   - Khi nh·∫•n n√∫t "Summarize", AI s·∫Ω t·ª± ƒë·ªông t·∫°o t√≥m t·∫Øt n·ªôi dung d·ª±a tr√™n transcript
   - T√≥m t·∫Øt ƒë∆∞·ª£c hi·ªÉn th·ªã nh∆∞ tin nh·∫Øn ƒë·∫ßu ti√™n trong chat

3. **Tr√≤ Chuy·ªán AI**:
   - H·ªçc vi√™n ƒë·∫∑t c√¢u h·ªèi li√™n quan ƒë·∫øn n·ªôi dung b√†i h·ªçc
   - Frontend g·ª≠i prompt ƒë·∫øn AI v·ªõi context t·ª´ transcript
   - AI tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi d·ª±a tr√™n n·ªôi dung b√†i h·ªçc

## 5. C√°c Prompt Templates

### 5.1. Prompt cho T√≥m T·∫Øt N·ªôi Dung

```typescript
// Khi c√≥ transcript
const summaryPromptWithTranscript = `
Summarize the following transcript - ${transcript} in context to ${courseName}
Provide a concise summary that highlights the main points, key concepts, and important examples from the lecture.
The summary should be structured with bullet points for key concepts.
Keep the tone educational and informative.
`;

// Khi kh√¥ng c√≥ transcript
const summaryPromptWithoutTranscript = `
mention "No transcript available for course!, But still here is a short summary on ${videoName}" and provide 3-4 line summary for ${videoName}
Based on the title, predict what the content might cover and provide a general overview of that topic.
Focus on standard concepts associated with this topic in programming education.
`;
```

### 5.2. Prompt cho C√¢u H·ªèi

```typescript
const questionPrompt = `
QUESTION - ${userQuestion} 
Answer the following question and provide answer in context to concepts associated with ${videoName} or ${courseName} only,
${transcript ? `Use following Transcript if required NOT Compulsory - "${transcript}" and` : "and"}
If question is out of context or not related to programming then just Send Response as "Please ask questions only related to ${videoName}".

Keep the answer concise but thorough, focusing on educational value.
Include code examples if appropriate for programming questions.
If a concept mentioned in the question appears in the transcript, reference and explain it.
If the question asks for clarification on something in the transcript, provide that clarification.
`;
```

## 6. C√†i ƒê·∫∑t API v√† Redux

### 6.1. Redux API Slice cho Transcript

```typescript
// Frontend/redux/features/courses/coursesApi.ts
export const coursesApi = apiSlice.injectEndpoints({
  endpoints: (builder) => ({
    // C√°c endpoints kh√°c...
    
    getTranscript: builder.mutation({
      query: ({ id, videoName }) => ({
        url: "get-transcript",
        method: "POST",
        body: { id, videoName },
        credentials: "include" as const,
      }),
    }),
  }),
});

export const {
  // C√°c hooks kh√°c...
  useGetTranscriptMutation,
} = coursesApi;
```

### 6.2. Backend Route

```typescript
// Backend/routes/course.route.ts
import express from "express";
import { authorizeRoles, isAuthenticated } from "../middleware/auth";
import { 
  // C√°c controllers kh√°c...
  getTranscript, 
  generateVideoSubtitle 
} from "../controller/course.controller";

const courseRouter = express.Router();

// C√°c routes kh√°c...

// Get transcript
courseRouter.post("/get-transcript", isAuthenticated, getTranscript);

// Generate subtitle (admin only)
courseRouter.post(
  "/generate-video-subtitle",
  isAuthenticated,
  authorizeRoles("admin"),
  generateVideoSubtitle
);

export default courseRouter;
```

## 7. Ph√¢n T√≠ch Hi·ªáu NƒÉng v√† T·ªëi ∆Øu

### 7.1. V·∫•n ƒê·ªÅ Hi·ªáu NƒÉng

1. **ƒê·ªô Tr·ªÖ API**: 
   - Google Generative AI c√≥ th·ªÉ c√≥ ƒë·ªô tr·ªÖ cao khi x·ª≠ l√Ω prompt d√†i
   - Vi·ªác t·∫°o transcript cho video d√†i c≈©ng ti√™u t·ªën th·ªùi gian v√† t√†i nguy√™n

2. **K√≠ch Th∆∞·ªõc Transcript**:
   - Transcript c·ªßa video d√†i c√≥ th·ªÉ r·∫•t l·ªõn, v∆∞·ª£t qu√° gi·ªõi h·∫°n c·ªßa prompt

3. **S·ª≠ D·ª•ng Token**:
   - Google Generative AI c√≥ gi·ªõi h·∫°n token, c·∫ßn t·ªëi ∆∞u vi·ªác s·ª≠ d·ª•ng

### 7.2. Gi·∫£i Ph√°p T·ªëi ∆Øu

1. **Caching**:
   - Cache transcript trong database ƒë·ªÉ tr√°nh t·∫°o l·∫°i m·ªói l·∫ßn
   - Cache c√°c c√¢u tr·∫£ l·ªùi th∆∞·ªùng g·∫∑p

2. **Chunk Transcript**:
   - Chia transcript th√†nh c√°c ƒëo·∫°n nh·ªè h∆°n
   - Ch·ªâ g·ª≠i c√°c ƒëo·∫°n li√™n quan ƒë·∫øn c√¢u h·ªèi

3. **Batch Processing**:
   - T·∫°o transcript trong background job
   - S·ª≠ d·ª•ng queue ƒë·ªÉ x·ª≠ l√Ω nhi·ªÅu y√™u c·∫ßu t·∫°o transcript

4. **T·ªëi ∆Øu Prompt**:
   - S·ª≠ d·ª•ng prompt ng·∫Øn g·ªçn v√† hi·ªáu qu·∫£
   - Ch·ªâ g·ª≠i context c·∫ßn thi·∫øt

```typescript
// V√≠ d·ª•: Chunk transcript
const chunkTranscript = (transcript: string, maxChunkSize: number = 2000): string[] => {
  const words = transcript.split(' ');
  const chunks: string[] = [];
  let currentChunk = '';

  for (const word of words) {
    if ((currentChunk + ' ' + word).length <= maxChunkSize) {
      currentChunk += (currentChunk ? ' ' : '') + word;
    } else {
      chunks.push(currentChunk);
      currentChunk = word;
    }
  }

  if (currentChunk) {
    chunks.push(currentChunk);
  }

  return chunks;
};

// S·ª≠ d·ª•ng chunks khi g·ª≠i prompt
const findRelevantChunk = (chunks: string[], question: string): string => {
  // T√¨m chunk li√™n quan nh·∫•t ƒë·∫øn c√¢u h·ªèi
  // (C√≥ th·ªÉ s·ª≠ d·ª•ng embedding ho·∫∑c keyword matching)
  // ...
  return mostRelevantChunk;
};
```

## 8. H∆∞·ªõng Ph√°t Tri·ªÉn Trong T∆∞∆°ng Lai

### 8.1. C√°c T√≠nh NƒÉng M·ªõi

1. **AI Tutor C√° Nh√¢n H√≥a**:
   - T·∫°o l·ªô tr√¨nh h·ªçc t·∫≠p c√° nh√¢n h√≥a d·ª±a tr√™n ti·∫øn ƒë·ªô v√† s·ªü th√≠ch c·ªßa h·ªçc vi√™n
   - ƒê·ªÅ xu·∫•t kh√≥a h·ªçc v√† b√†i h·ªçc ph√π h·ª£p

2. **Sinh N·ªôi Dung T·ª± ƒê·ªông**:
   - T·ª± ƒë·ªông t·∫°o quiz v√† b√†i t·∫≠p t·ª´ n·ªôi dung b√†i h·ªçc
   - T·∫°o flashcards v√† t√†i li·ªáu √¥n t·∫≠p

3. **Ph√¢n T√≠ch D·ªØ Li·ªáu H·ªçc T·∫≠p**:
   - Ph√¢n t√≠ch h√†nh vi h·ªçc t·∫≠p c·ªßa h·ªçc vi√™n
   - ƒê∆∞a ra g·ª£i √Ω c·∫£i thi·ªán hi·ªáu qu·∫£ h·ªçc t·∫≠p

4. **ƒêa Ng√¥n Ng·ªØ**:
   - D·ªãch n·ªôi dung kh√≥a h·ªçc sang nhi·ªÅu ng√¥n ng·ªØ
   - H·ªó tr·ª£ tr√≤ chuy·ªán AI b·∫±ng nhi·ªÅu ng√¥n ng·ªØ

### 8.2. C·∫£i Ti·∫øn AI

1. **Fine-tuning Model**:
   - Fine-tune model Gemini v·ªõi d·ªØ li·ªáu t·ª´ lƒ©nh v·ª±c c·ª• th·ªÉ
   - T·∫°o model chuy√™n bi·ªát cho t·ª´ng ch·ªß ƒë·ªÅ (l·∫≠p tr√¨nh, thi·∫øt k·∫ø, v.v.)

2. **Embedding Vector Database**:
   - S·ª≠ d·ª•ng embedding ƒë·ªÉ l∆∞u tr·ªØ v√† t√¨m ki·∫øm n·ªôi dung
   - T√¨m ki·∫øm semantic thay v√¨ keyword

3. **Multi-modal AI**:
   - Ph√¢n t√≠ch h√¨nh ·∫£nh v√† video ƒë·ªÉ hi·ªÉu n·ªôi dung
   - T·∫°o gi·∫£i th√≠ch cho c√°c ƒëo·∫°n code v√† diagram

4. **Realtime AI Feedback**:
   - Cung c·∫•p ph·∫£n h·ªìi realtime khi h·ªçc vi√™n l√†m b√†i t·∫≠p
   - Ph√°t hi·ªán v√† s·ª≠a l·ªói trong code

## 9. C√°c Th√°ch Th·ª©c v√† Gi·∫£i Ph√°p

### 9.1. Th√°ch Th·ª©c

1. **ƒê·ªô Ch√≠nh X√°c c·ªßa Transcript**:
   - Transcript c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c ƒë·ªëi v·ªõi c√°c thu·∫≠t ng·ªØ k·ªπ thu·∫≠t
   - Sai s√≥t trong ph√°t √¢m v√† ng√¥n ng·ªØ chuy√™n ng√†nh

2. **Hallucination c·ªßa AI**:
   - AI c√≥ th·ªÉ t·∫°o ra th√¥ng tin kh√¥ng c√≥ trong n·ªôi dung kh√≥a h·ªçc
   - Thi·∫øu ch√≠nh x√°c trong c√°c c√¢u tr·∫£ l·ªùi k·ªπ thu·∫≠t

3. **Chi Ph√≠ API**:
   - Chi ph√≠ API c·ªßa Google Generative AI tƒÉng theo s·ªë l∆∞·ª£ng ng∆∞·ªùi d√πng
   - T·∫°o transcript cho video d√†i r·∫•t t·ªën k√©m

4. **Ng√¥n Ng·ªØ ƒêa D·∫°ng**:
   - H·ªçc vi√™n c√≥ th·ªÉ ƒë·∫∑t c√¢u h·ªèi b·∫±ng nhi·ªÅu ng√¥n ng·ªØ kh√°c nhau
   - N·ªôi dung kh√≥a h·ªçc c√≥ th·ªÉ b·∫±ng nhi·ªÅu ng√¥n ng·ªØ

### 9.2. Gi·∫£i Ph√°p

1. **Ki·ªÉm Tra v√† Ch·ªânh S·ª≠a Transcript**:
   - Cho ph√©p gi·∫£ng vi√™n ch·ªânh s·ª≠a transcript
   - S·ª≠ d·ª•ng dictionary c·ªßa thu·∫≠t ng·ªØ k·ªπ thu·∫≠t ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c

2. **Prompt Engineering N√¢ng Cao**:
   - Thi·∫øt k·∫ø prompt gi·∫£m thi·ªÉu hallucination
   - Th√™m h∆∞·ªõng d·∫´n c·ª• th·ªÉ cho AI ƒë·ªÉ tr√°nh t·∫°o th√¥ng tin sai

3. **Qu·∫£n L√Ω Chi Ph√≠ API**:
   - S·ª≠ d·ª•ng caching ƒë·ªÉ gi·∫£m s·ªë l∆∞·ª£ng g·ªçi API
   - Thi·∫øt l·∫≠p gi·ªõi h·∫°n s·ª≠ d·ª•ng theo g√≥i d·ªãch v·ª•

4. **H·ªó Tr·ª£ ƒêa Ng√¥n Ng·ªØ**:
   - T·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ c·ªßa c√¢u h·ªèi
   - S·ª≠ d·ª•ng prompt ƒëa ng√¥n ng·ªØ